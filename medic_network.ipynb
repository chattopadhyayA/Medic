{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e9b39715",
   "metadata": {},
   "source": [
    "# Medic Network Notebook\n",
    "\n",
    "In this notebook we will use the medic network declared in the utility file medica.py, for training and testing on our generated dataset. The dataset has been created through the Data_create.ipynb notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae52e4f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# collider_doctor_v1\n",
    "# Neural network for collider data: track, tower, missinget â†’ 4-class probability distribution\n",
    "\n",
    "import awkward as ak\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from medica import *"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "880ed816",
   "metadata": {},
   "source": [
    "## Loading the data for training/testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "770a08c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Params\n",
    "json_path = \"Data/training_data.json\"\n",
    "batch_size = 64\n",
    "lr = 1e-3\n",
    "epochs = 300\n",
    "patience = 20\n",
    "\n",
    "# Load dataset & split\n",
    "data = read_json_to_awkward(json_path)\n",
    "\n",
    "# converting awkward array to torch Dataset\n",
    "dataset = ColliderDataset(data)\n",
    "\n",
    "# Printing the dataset information\n",
    "print(\"Total events in dataset:\", len(dataset))\n",
    "# Peek at one example\n",
    "track, tower, met, y = dataset[0]\n",
    "print(\"Track features:\", track.shape[2])\n",
    "track_features = track.shape[2]\n",
    "print(\"Tower fetures:\", tower.shape[2])\n",
    "tower_features = tower.shape[2]\n",
    "print(\"Missing ET features:\", met.shape[2])\n",
    "met_features = met.shape[2]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33f125d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting the dataset into train, validation, and test sets\n",
    "n_total = len(dataset)\n",
    "n_train = int(0.7 * n_total)\n",
    "n_val = int(0.1 * n_total)\n",
    "n_test = n_total - n_train - n_val\n",
    "train_set, val_set, test_set = random_split(dataset, [n_train, n_val, n_test])\n",
    "train_loader = DataLoader(train_set, batch_size=batch_size, shuffle=True)\n",
    "val_loader = DataLoader(val_set, batch_size=batch_size)\n",
    "test_loader = DataLoader(test_set, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7e3ea2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Setup model/optimizer/loss/device\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "embed_dim = 64\n",
    "model = MEDIC(d_track=track_features, d_tower=tower_features, d_met=met_features, embed_dim=embed_dim).to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "criterion = nn.KLDivLoss(reduction=\"batchmean\")\n",
    "\n",
    "# Train\n",
    "model = train_model(model, train_loader, val_loader, optimizer, criterion, device, epochs, patience)\n",
    "\n",
    "# Test\n",
    "test_model(model, test_loader, criterion, device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f31cb7b4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "jarv_root",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
