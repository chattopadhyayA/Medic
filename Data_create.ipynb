{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "72c78dc5",
   "metadata": {},
   "source": [
    "# Creating the Training dataset\n",
    "\n",
    "In this notebook we will read from the data files generated with Madgraph + Pythia +Delphes simulation and create a training/testing dataset for the LHCdoctor network."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "247655db",
   "metadata": {},
   "source": [
    "### Getting all the headers ready"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c247173a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import awkward as ak\n",
    "import uproot\n",
    "\n",
    "from medica import *"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae875708",
   "metadata": {},
   "source": [
    "### Reading from the Json file\n",
    "\n",
    "Here we are assuming that all the data are saved in a file with the path \"Data/shuffled_data.json\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6147f45e",
   "metadata": {},
   "outputs": [],
   "source": [
    "Data_Path = \"Data/shuffled_data.json\"\n",
    "\n",
    "full_data = read_json_to_awkward(Data_Path)\n",
    "\n",
    "# Getting all top-level branches and their information \n",
    "branch_info (full_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10e7100c",
   "metadata": {},
   "source": [
    "Now we need to refine the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3e41b79",
   "metadata": {},
   "outputs": [],
   "source": [
    "track_to_retain = 10 # minimum number of tracks per event\n",
    "tower_to_retain = 10 # minimum number of towers per event\n",
    "Refined_data = refinement(full_data, 10, 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd0fc129",
   "metadata": {},
   "source": [
    "So, we have the above number of events where there are atleast 10 track info and 10 tower info."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf36cb4d",
   "metadata": {},
   "source": [
    "### Dataset creation\n",
    "\n",
    "\n",
    "Now we will split the refined data in the window of say $10$ events, and we will randomly choose $30$ track parameters as well as $30$ tower paramaters for each of this events"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "636c24fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "window_size = 10 # size of the data-window\n",
    "event_tower_to_retain = 30 # number of towers to retain per event\n",
    "event_track_to_retain = 30 # number of tracks to retain per event\n",
    "\n",
    "X_tracks, X_towers, X_missinget, y, training_dataset = Dataset_Creator(Refined_data, window=window_size, \n",
    "                                                                       event_tower=event_tower_to_retain, \n",
    "                                                                       event_track=event_track_to_retain, seed=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91092f3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_dataset.type.show()\n",
    "branch_info (training_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f09bc6a",
   "metadata": {},
   "source": [
    "## Timeseries dataset creation\n",
    "\n",
    "\n",
    "We can also mimick a real scenario by adding new data to the window. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fc02b0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "window_size = 10 # size of the sliding window\n",
    "Save_Path = f\"Data/training_data_w_{window_size}.json\" # path to save the created dataset\n",
    "event_tower_to_retain = 30 # number of towers to retain per event\n",
    "event_track_to_retain = 30 # number of tracks to retain per event\n",
    "\n",
    "X_tracks, X_towers, X_missinget, y, training_dataset = Sliding_Window_Dataset_Creator(Refined_data, window=window_size, \n",
    "                                                                                      event_tower=event_tower_to_retain, \n",
    "                                                                                      event_track=event_track_to_retain, seed=42, \n",
    "                                                                                      save_json_path=Save_Path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "995c05a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_dataset.type.show()\n",
    "branch_info (training_dataset)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "jarv_root",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
